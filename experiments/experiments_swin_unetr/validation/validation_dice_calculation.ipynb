{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " missing cuda symbols while dynamic loading\n",
      " cuFile initialization failed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from monai.networks.nets import SwinUNETR\n",
    "import json\n",
    "import os\n",
    "import monai\n",
    "import shutil\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureChannelFirstd,\n",
    "    SpatialPadd,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_final = json.load(open(os.path.join(\"/nnUNet/preprocessed_data/Dataset060_Merged_Def/\", \"splits_Dataset060_Merged_Def.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = [160, 64, 128]\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim=\"no_channel\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.5, 1.5, 1.5),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-982,\n",
    "            a_max=1094,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        SpatialPadd(keys=[\"image\", \"label\"], spatial_size=patch_size),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate predictions of validation set per fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples_per_image = 2\n",
    "\n",
    "post_label = monai.transforms.AsDiscrete(to_onehot=13)\n",
    "post_pred = monai.transforms.AsDiscrete(argmax=True, to_onehot=13)\n",
    "post_pred_to_save = monai.transforms.AsDiscrete(argmax=True)\n",
    "\n",
    "data_dir = \"/nnUNet/raw_data/Dataset060_Merged_Def/\"\n",
    "\n",
    "for fold in range(0, 5):\n",
    "\n",
    "    results = {}\n",
    "    results['metric_per_case'] = []\n",
    "\n",
    "    # Initialize model with weights of each fold\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = SwinUNETR(\n",
    "    img_size=patch_size,\n",
    "    in_channels=1,\n",
    "    out_channels=13,\n",
    "    feature_size=48,\n",
    "    use_checkpoint=True,\n",
    "    ).to(device)\n",
    "\n",
    "    weight = torch.load(f\"/experiments_Swin-UNETR/fold_{fold}/output/swin_unetr_fold_{fold}_best_metric_model.pth\")\n",
    "    model.load_state_dict(weight['state_dict'])\n",
    "\n",
    "\n",
    "    # Load validation set\n",
    "\n",
    "    val_images = []\n",
    "    val_labels = []\n",
    "\n",
    "    for image_name in splits_final[fold][\"val\"]:\n",
    "        val_images.append(os.path.join(data_dir, \"imagesTr\", image_name + \"_0000.nii.gz\"))\n",
    "        val_labels.append(os.path.join(data_dir, \"labelsTr\", image_name + \".nii.gz\"))\n",
    "\n",
    "    val_images = sorted(val_images)\n",
    "    val_labels = sorted(val_labels)\n",
    "\n",
    "    val_files = [\n",
    "    {\"image\": image_name, \"label\": label_name, 'path': image_name}\n",
    "    for image_name, label_name in zip(val_images, val_labels)\n",
    "    ]\n",
    "\n",
    "    val_ds = monai.data.CacheDataset(data=val_files, transform=val_transforms, num_workers=7)\n",
    "    val_loader = monai.data.DataLoader(val_ds, batch_size=1)\n",
    "\n",
    "    # Calculate validation Dice score\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, test_data in enumerate(val_loader):\n",
    "            results['metric_per_case'].append({})\n",
    "            \n",
    "            test_volume = test_data[\"image\"]\n",
    "            test_label = test_data[\"label\"]\n",
    "            test_volume_no_preprocess = monai.transforms.LoadImage()(test_data[\"path\"])\n",
    "            test_volume, test_label = (\n",
    "                test_volume.to(device),\n",
    "                test_label.to(device),\n",
    "            )\n",
    "\n",
    "            test_outputs = monai.inferers.sliding_window_inference(test_volume, patch_size, num_samples_per_image, model, overlap=0.5)\n",
    "\n",
    "            # CODE TO SAVE IMAGES\n",
    "            prediction = post_pred_to_save(test_outputs[0])\n",
    "\n",
    "            prediction = monai.transforms.ResampleToMatch()(img=prediction, img_dst=torch.unsqueeze(test_volume_no_preprocess, axis=0), mode='nearest')\n",
    "\n",
    "            monai.transforms.SaveImage(output_dir=f\"/swin_unetr/inference/fold_{fold}/\", output_postfix='', separate_folder=False)(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnunet_dice(mask_pred: np.ndarray, mask_ref: np.ndarray):\n",
    "    dice_scores = []\n",
    "    for organ_class in range(1, 13):\n",
    "        gt = (mask_ref == organ_class)\n",
    "        pred = (mask_pred == organ_class)\n",
    "        use_mask = np.ones_like(gt, dtype=bool)\n",
    "        \n",
    "        tp = np.sum((gt & pred) & use_mask)\n",
    "        fp = np.sum(((~gt) & pred) & use_mask)\n",
    "        fn = np.sum((gt & (~pred)) & use_mask)\n",
    "        \n",
    "        if tp + fp + fn == 0:\n",
    "            dice_scores.append(np.nan)\n",
    "        else:\n",
    "            dice_scores.append(2 * tp / (2 * tp + fp + fn))\n",
    "    \n",
    "    return dice_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [04:06<00:00, 246.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CODE TO CALCULATE VALIDATION DICE SCORES AND SAVE THEM IN A JSON FILE\n",
    "\n",
    "import monai.transforms\n",
    "\n",
    "\n",
    "load_img = monai.transforms.LoadImage(ensure_channel_first=True)\n",
    "\n",
    "for fold in tqdm(range(4, 5)):\n",
    "    results = {}\n",
    "    results['metric_per_case'] = []\n",
    "\n",
    "    preds_folder = f\"/swin_unetr/inference/fold_{fold}/preds\"\n",
    "    gt_folder = f\"/swin_unetr/inference/fold_{fold}/gt\"\n",
    "    for i, pred_name in enumerate(sorted(os.listdir(preds_folder))):\n",
    "        results['metric_per_case'].append({})\n",
    "        \n",
    "        gt = load_img(os.path.join(gt_folder, pred_name))\n",
    "        pred = load_img(os.path.join(preds_folder, pred_name))\n",
    "        dice_score = nnunet_dice(pred, gt)\n",
    "\n",
    "        results['metric_per_case'][i]['metrics'] = {}\n",
    "        for j in range(1, 13):\n",
    "            results['metric_per_case'][i]['metrics'][str(j)] = dice_score[j-1]\n",
    "        results['metric_per_case'][i]['prediction_file'] = os.path.join(preds_folder, pred_name)\n",
    "        results['metric_per_case'][i]['reference_file'] = os.path.join(gt_folder, pred_name)\n",
    "        \n",
    "    with open(f\"/experiments_Swin-UNETR/validation_dice_calculation/validation_results_per_fold/summary_fold_{fold}.json\", \"w\") as outfile:\n",
    "        json.dump(results, outfile)\n",
    "        print('File saved successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE TO READ JSON FILES AND APPEND DICE SCORES PER ORGAN - ITS GOAL IS TO CALCULATE THE MEAN DICE PER ORGAN FOR ALL FOLDS\n",
    "\n",
    "res = []\n",
    "means = []\n",
    "\n",
    "for i in range(0, 5):\n",
    "    results = {}\n",
    "    results['metric_per_case'] = []\n",
    "    \n",
    "    summary = json.load(open(f\"/experiments_Swin-UNETR/validation_dice_calculation/validation_results_per_fold/summary_fold_{i}.json\"))\n",
    "    for case in summary['metric_per_case']:\n",
    "        res = []\n",
    "        for key in range(1, 13):\n",
    "            res.append(case['metrics'][str(key)])\n",
    "        means.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.961 0.952 0.947 0.826 0.833 0.976 0.921 0.949 0.903 0.861 0.788 0.785]\n",
      "0.892\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(means, axis=0).round(3))\n",
    "print(np.mean(means).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge fold summaries into a single one (cross val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = json.load(open(\"/experiments_Swin-UNETR/validation_dice_calculation/validation_results_per_fold/summary_fold_0.json\"))\n",
    "f1 = json.load(open(\"/experiments_Swin-UNETR/validation_dice_calculation/validation_results_per_fold/summary_fold_1.json\"))\n",
    "f2 = json.load(open(\"/experiments_Swin-UNETR/validation_dice_calculation/validation_results_per_fold/summary_fold_2.json\"))\n",
    "f3 = json.load(open(\"/experiments_Swin-UNETR/validation_dice_calculation/validation_results_per_fold/summary_fold_3.json\"))\n",
    "f4 = json.load(open(\"/experiments_Swin-UNETR/validation_dice_calculation/validation_results_per_fold/summary_fold_4.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val = {'metric_per_case': []}\n",
    "\n",
    "for fold in [f0, f1, f2, f3, f4]:\n",
    "    for case in fold['metric_per_case']:\n",
    "        cross_val['metric_per_case'].append(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/experiments_Swin-UNETR/validation_dice_calculation/validation_results_per_fold/summary_cross_val.json\", \"w\") as outfile:\n",
    "        json.dump(cross_val, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
